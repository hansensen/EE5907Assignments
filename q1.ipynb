{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import DataLoader as dl\n",
    "import math\n",
    "\n",
    "# Binarization preprocessing\n",
    "def binarization(a):\n",
    "\tbinarizer = preprocessing.Binarizer().fit(a)\n",
    "\treturn binarizer.transform(a)\n",
    "\n",
    "# Compute Maximum Likelihood Estimation of lambda\n",
    "def getLambdaML(data):\n",
    "\ta = np.array(data)\n",
    "\tunique, counts = np.unique(a, return_counts=True)\n",
    "\tlabels = dict(zip(unique, counts))\n",
    "\t# ML Estimate of lambda = N1/N\n",
    "\tlambdaMl = labels[1]/(labels[0]+labels[1])\n",
    "\treturn lambdaMl, labels[0], labels[1]+labels[0]\n",
    "\n",
    "def getNbClassifier(xtrain, ytrain):\n",
    "\t# lambdaMl = getLambdaML(ytrain)\n",
    "\t# Separate xtrain by class/label\n",
    "\tspam = []\n",
    "\tnonspam = []\n",
    "\tfor i in range(len(xtrain)):\n",
    "\t\tvector = xtrain[i]\n",
    "\t\tif ytrain[i] == 0:\n",
    "\t\t\tnonspam.append(vector)\n",
    "\t\telse:\n",
    "\t\t\tspam.append(vector)\n",
    "\tspam = np.array(spam).astype(int)\n",
    "\tnonspam = np.array(nonspam).astype(int)\n",
    "\t# calculate Xcj matrix\n",
    "\tnumFeatures = spam.shape[1]\n",
    "\tprint('Feauture Number: ', numFeatures)\n",
    "\tx = np.zeros((2, numFeatures)).astype(int)\n",
    "\tx[1] = np.sum(spam, axis=0)\n",
    "\tx[0] = np.sum(nonspam, axis=0)\n",
    "\tprint(x[0])\n",
    "\tprint(x[1])\n",
    "\treturn x\n",
    "\n",
    "def getPredictions(classifier, xtest):\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [1. 0. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Load data from spamData.mat\n",
    "xtrain, ytrain, xtest, ytest = dl.loadData('spamData.mat')\n",
    "xtrain = binarization(xtrain)\n",
    "xtest = binarization(xtest)\n",
    "print(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feauture Number:  57\n",
      "[ 260  176  497    6  394  218   29  140  135  319   96  776  203   82\n",
      "   33  172  168  227 1037   29  617    9   52   35  672  508  499  274\n",
      "  227  280  176  127  229  128  267  309  471   34  210  155   94  204\n",
      "  182  166  526  287   26  122  337 1000  249  479  184  146 1825 1825\n",
      " 1825]\n",
      "[ 431  433  760   25  783  457  523  444  394  582  391  785  357  151\n",
      "  202  692  489  476 1102  274 1006   57  416  461   38   18    7   19\n",
      "    8    9    3    2   48    7   37   81   72   23   51  144    1   12\n",
      "   58   28  321   54   12   11  191  801   88 1033  761  358 1240 1240\n",
      " 1240]\n"
     ]
    }
   ],
   "source": [
    "# Get classifier\n",
    "naiveBayesClassifier = getNbClassifier(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.40456769983686786, 1825, 3065)\n"
     ]
    }
   ],
   "source": [
    "# Get Maximum Likelihood Estimation of lambda\n",
    "lambdaMl, N1, N = getLambdaML(ytrain)\n",
    "print(getLambdaML(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.    0.5   1.    1.5   2.    2.5   3.    3.5   4.    4.5   5.    5.5\n",
      "   6.    6.5   7.    7.5   8.    8.5   9.    9.5  10.   10.5  11.   11.5\n",
      "  12.   12.5  13.   13.5  14.   14.5  15.   15.5  16.   16.5  17.   17.5\n",
      "  18.   18.5  19.   19.5  20.   20.5  21.   21.5  22.   22.5  23.   23.5\n",
      "  24.   24.5  25.   25.5  26.   26.5  27.   27.5  28.   28.5  29.   29.5\n",
      "  30.   30.5  31.   31.5  32.   32.5  33.   33.5  34.   34.5  35.   35.5\n",
      "  36.   36.5  37.   37.5  38.   38.5  39.   39.5  40.   40.5  41.   41.5\n",
      "  42.   42.5  43.   43.5  44.   44.5  45.   45.5  46.   46.5  47.   47.5\n",
      "  48.   48.5  49.   49.5  50.   50.5  51.   51.5  52.   52.5  53.   53.5\n",
      "  54.   54.5  55.   55.5  56.   56.5  57.   57.5  58.   58.5  59.   59.5\n",
      "  60.   60.5  61.   61.5  62.   62.5  63.   63.5  64.   64.5  65.   65.5\n",
      "  66.   66.5  67.   67.5  68.   68.5  69.   69.5  70.   70.5  71.   71.5\n",
      "  72.   72.5  73.   73.5  74.   74.5  75.   75.5  76.   76.5  77.   77.5\n",
      "  78.   78.5  79.   79.5  80.   80.5  81.   81.5  82.   82.5  83.   83.5\n",
      "  84.   84.5  85.   85.5  86.   86.5  87.   87.5  88.   88.5  89.   89.5\n",
      "  90.   90.5  91.   91.5  92.   92.5  93.   93.5  94.   94.5  95.   95.5\n",
      "  96.   96.5  97.   97.5  98.   98.5  99.   99.5 100. ]\n"
     ]
    }
   ],
   "source": [
    "# Create an array of alpha values, from 0 to 100 with step size 0.5\n",
    "alphaStart = 0\n",
    "alphaEnd = 100\n",
    "alphaStepSize = 0.5\n",
    "alphaArr = np.arange(alphaStart, alphaEnd + alphaStepSize, alphaStepSize)\n",
    "print(alphaArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "# Initialise an array of error rate\n",
    "errRate = np.zeros(alphaArr.size)\n",
    "print(alphaArr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureVector [0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('featureVector', xtest[0])\n",
    "featureVector = xtest[0]\n",
    "#print(calcPosteriorProdictiveDist(alpha, naiveBayesClassifier, lambdaMl, featureVector))\n",
    "range(featureVector.shape[0])\n",
    "featureVector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calcPosteriorProdictiveDist(alpha, naiveBayesClassifier, lambdaMl, featureVector):\n",
    "\t# Initialise\n",
    "\tlambdaMlArr = np.array([1 - lambdaMl, lambdaMl])\n",
    "\tlogP_yTilde = np.log(lambdaMlArr)\n",
    "\t#print('lambdaMlArr ',logP_yTilde)\n",
    "    \n",
    "\t#print('featureVector ', featureVector)\n",
    "\t#print('p(y=0):')\n",
    "\n",
    "\t# Calculate  logP(yTilde = 0 | xTilde, D)\n",
    "\tfor i in range(featureVector.shape[0]):\n",
    "\t\tfeature = featureVector[i]\n",
    "\t\tif (feature):\n",
    "\t\t\tn1 = naiveBayesClassifier[0][i]\n",
    "\t\telse:\n",
    "\t\t\tn1 = N1 - naiveBayesClassifier[0][i]\n",
    "\t\tprior = (n1 + alpha)/(N1 + 2* alpha)\n",
    "\t\t#print('n1: ', n1, 'N: ', N1)\n",
    "\t\t#print('prior: ', prior)\n",
    "\t\tif prior == 0:\n",
    "\t\t\tprior = 0.00000001;\n",
    "\t\t#print('logP_yTilde', logP_yTilde[0])\n",
    "\t\tlogP_yTilde[0] += math.log(prior)\n",
    "        \n",
    "\t#print('p(y=1):')\n",
    "\t# Calculate  logP(yTilde = 1 | xTilde, D)\n",
    "\tfor i in range(featureVector.shape[0]):\n",
    "\t\tfeature = featureVector[i]\n",
    "\t\tif (feature):\n",
    "\t\t\tn1 = naiveBayesClassifier[1][i]\n",
    "\t\telse:\n",
    "\t\t\tn1 = N - N1 - naiveBayesClassifier[1][i]\n",
    "\t\t#print('n1: ', n1, 'N: ', N - N1)\n",
    "\t\tprior = (n1 + alpha)/((N - N1) + 2* alpha)\n",
    "\t\t#print('prior: ', prior)\n",
    "\t\tif prior == 0:\n",
    "\t\t\tprior = 0.00000001;\n",
    "\t\tlogP_yTilde[1] += math.log(prior)\n",
    "\t#print('logP_yTilde_0',logP_yTilde[0])\n",
    "\t#print('logP_yTilde_1',logP_yTilde[1])\n",
    "\tif logP_yTilde[0] > logP_yTilde[1]:\n",
    "\t\treturn 0\n",
    "\telse:\n",
    "\t\treturn 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.0\n",
      "0.12044270833333333\n",
      "alpha:  0.5\n",
      "0.12174479166666667\n",
      "alpha:  1.0\n",
      "0.12369791666666667\n",
      "alpha:  1.5\n",
      "0.12434895833333333\n",
      "alpha:  2.0\n",
      "0.125\n",
      "alpha:  2.5\n",
      "0.12565104166666666\n",
      "alpha:  3.0\n",
      "0.12565104166666666\n",
      "alpha:  3.5\n",
      "0.126953125\n",
      "alpha:  4.0\n",
      "0.12630208333333334\n",
      "alpha:  4.5\n",
      "0.12630208333333334\n",
      "alpha:  5.0\n",
      "0.126953125\n",
      "alpha:  5.5\n",
      "0.12565104166666666\n",
      "alpha:  6.0\n",
      "0.12565104166666666\n",
      "alpha:  6.5\n",
      "0.12565104166666666\n",
      "alpha:  7.0\n",
      "0.12565104166666666\n",
      "alpha:  7.5\n",
      "0.12565104166666666\n",
      "alpha:  8.0\n",
      "0.12565104166666666\n",
      "alpha:  8.5\n",
      "0.12565104166666666\n",
      "alpha:  9.0\n",
      "0.126953125\n",
      "alpha:  9.5\n",
      "0.126953125\n",
      "alpha:  10.0\n",
      "0.126953125\n",
      "alpha:  10.5\n",
      "0.12760416666666666\n",
      "alpha:  11.0\n",
      "0.12760416666666666\n",
      "alpha:  11.5\n",
      "0.12760416666666666\n",
      "alpha:  12.0\n",
      "0.12760416666666666\n",
      "alpha:  12.5\n",
      "0.12760416666666666\n",
      "alpha:  13.0\n",
      "0.12825520833333334\n",
      "alpha:  13.5\n",
      "0.12825520833333334\n",
      "alpha:  14.0\n",
      "0.12825520833333334\n",
      "alpha:  14.5\n",
      "0.12825520833333334\n",
      "alpha:  15.0\n",
      "0.12825520833333334\n",
      "alpha:  15.5\n",
      "0.12825520833333334\n",
      "alpha:  16.0\n",
      "0.12825520833333334\n",
      "alpha:  16.5\n",
      "0.12825520833333334\n",
      "alpha:  17.0\n",
      "0.12890625\n",
      "alpha:  17.5\n",
      "0.12955729166666666\n",
      "alpha:  18.0\n",
      "0.12955729166666666\n",
      "alpha:  18.5\n",
      "0.12955729166666666\n",
      "alpha:  19.0\n",
      "0.13020833333333334\n",
      "alpha:  19.5\n",
      "0.13216145833333334\n",
      "alpha:  20.0\n",
      "0.13216145833333334\n",
      "alpha:  20.5\n",
      "0.13216145833333334\n",
      "alpha:  21.0\n",
      "0.1328125\n",
      "alpha:  21.5\n",
      "0.13346354166666666\n",
      "alpha:  22.0\n",
      "0.13346354166666666\n",
      "alpha:  22.5\n",
      "0.13346354166666666\n",
      "alpha:  23.0\n",
      "0.1328125\n",
      "alpha:  23.5\n",
      "0.13346354166666666\n",
      "alpha:  24.0\n",
      "0.13346354166666666\n",
      "alpha:  24.5\n",
      "0.13346354166666666\n",
      "alpha:  25.0\n",
      "0.13346354166666666\n",
      "alpha:  25.5\n",
      "0.13346354166666666\n",
      "alpha:  26.0\n",
      "0.1328125\n",
      "alpha:  26.5\n",
      "0.13346354166666666\n",
      "alpha:  27.0\n",
      "0.13346354166666666\n",
      "alpha:  27.5\n",
      "0.13346354166666666\n",
      "alpha:  28.0\n",
      "0.13346354166666666\n",
      "alpha:  28.5\n",
      "0.13346354166666666\n",
      "alpha:  29.0\n",
      "0.13346354166666666\n",
      "alpha:  29.5\n",
      "0.1328125\n",
      "alpha:  30.0\n",
      "0.1328125\n",
      "alpha:  30.5\n",
      "0.1328125\n",
      "alpha:  31.0\n",
      "0.13346354166666666\n",
      "alpha:  31.5\n",
      "0.13346354166666666\n",
      "alpha:  32.0\n",
      "0.13346354166666666\n",
      "alpha:  32.5\n",
      "0.13346354166666666\n",
      "alpha:  33.0\n",
      "0.13346354166666666\n",
      "alpha:  33.5\n",
      "0.13346354166666666\n",
      "alpha:  34.0\n",
      "0.13411458333333334\n",
      "alpha:  34.5\n",
      "0.13411458333333334\n",
      "alpha:  35.0\n",
      "0.13411458333333334\n",
      "alpha:  35.5\n",
      "0.13411458333333334\n",
      "alpha:  36.0\n",
      "0.13411458333333334\n",
      "alpha:  36.5\n",
      "0.13541666666666666\n",
      "alpha:  37.0\n",
      "0.13541666666666666\n",
      "alpha:  37.5\n",
      "0.13606770833333334\n",
      "alpha:  38.0\n",
      "0.13606770833333334\n",
      "alpha:  38.5\n",
      "0.13606770833333334\n",
      "alpha:  39.0\n",
      "0.13606770833333334\n",
      "alpha:  39.5\n",
      "0.13606770833333334\n",
      "alpha:  40.0\n",
      "0.13606770833333334\n",
      "alpha:  40.5\n",
      "0.13606770833333334\n",
      "alpha:  41.0\n",
      "0.13671875\n",
      "alpha:  41.5\n",
      "0.13671875\n",
      "alpha:  42.0\n",
      "0.13671875\n",
      "alpha:  42.5\n",
      "0.13671875\n",
      "alpha:  43.0\n",
      "0.13671875\n",
      "alpha:  43.5\n",
      "0.13671875\n",
      "alpha:  44.0\n",
      "0.13671875\n",
      "alpha:  44.5\n",
      "0.13671875\n",
      "alpha:  45.0\n",
      "0.13671875\n",
      "alpha:  45.5\n",
      "0.13671875\n",
      "alpha:  46.0\n",
      "0.13736979166666666\n",
      "alpha:  46.5\n",
      "0.13736979166666666\n",
      "alpha:  47.0\n",
      "0.13736979166666666\n",
      "alpha:  47.5\n",
      "0.13736979166666666\n",
      "alpha:  48.0\n",
      "0.13736979166666666\n",
      "alpha:  48.5\n",
      "0.13736979166666666\n",
      "alpha:  49.0\n",
      "0.13736979166666666\n",
      "alpha:  49.5\n",
      "0.13736979166666666\n",
      "alpha:  50.0\n",
      "0.13736979166666666\n",
      "alpha:  50.5\n",
      "0.13736979166666666\n",
      "alpha:  51.0\n",
      "0.13802083333333334\n",
      "alpha:  51.5\n",
      "0.138671875\n",
      "alpha:  52.0\n",
      "0.13932291666666666\n",
      "alpha:  52.5\n",
      "0.13932291666666666\n",
      "alpha:  53.0\n",
      "0.13932291666666666\n",
      "alpha:  53.5\n",
      "0.13932291666666666\n",
      "alpha:  54.0\n",
      "0.13932291666666666\n",
      "alpha:  54.5\n",
      "0.13932291666666666\n",
      "alpha:  55.0\n",
      "0.13932291666666666\n",
      "alpha:  55.5\n",
      "0.13932291666666666\n",
      "alpha:  56.0\n",
      "0.13997395833333334\n",
      "alpha:  56.5\n",
      "0.13997395833333334\n",
      "alpha:  57.0\n",
      "0.13997395833333334\n",
      "alpha:  57.5\n",
      "0.13997395833333334\n",
      "alpha:  58.0\n",
      "0.13997395833333334\n",
      "alpha:  58.5\n",
      "0.13997395833333334\n",
      "alpha:  59.0\n",
      "0.13997395833333334\n",
      "alpha:  59.5\n",
      "0.13997395833333334\n",
      "alpha:  60.0\n",
      "0.13997395833333334\n",
      "alpha:  60.5\n",
      "0.13997395833333334\n",
      "alpha:  61.0\n",
      "0.13997395833333334\n",
      "alpha:  61.5\n",
      "0.13997395833333334\n",
      "alpha:  62.0\n",
      "0.13997395833333334\n",
      "alpha:  62.5\n",
      "0.140625\n",
      "alpha:  63.0\n",
      "0.140625\n",
      "alpha:  63.5\n",
      "0.140625\n",
      "alpha:  64.0\n",
      "0.140625\n",
      "alpha:  64.5\n",
      "0.140625\n",
      "alpha:  65.0\n",
      "0.140625\n",
      "alpha:  65.5\n",
      "0.140625\n",
      "alpha:  66.0\n",
      "0.14192708333333334\n",
      "alpha:  66.5\n",
      "0.14192708333333334\n",
      "alpha:  67.0\n",
      "0.14192708333333334\n",
      "alpha:  67.5\n",
      "0.14192708333333334\n",
      "alpha:  68.0\n",
      "0.14192708333333334\n",
      "alpha:  68.5\n",
      "0.142578125\n",
      "alpha:  69.0\n",
      "0.142578125\n",
      "alpha:  69.5\n",
      "0.142578125\n",
      "alpha:  70.0\n",
      "0.142578125\n",
      "alpha:  70.5\n",
      "0.142578125\n",
      "alpha:  71.0\n",
      "0.142578125\n",
      "alpha:  71.5\n",
      "0.142578125\n",
      "alpha:  72.0\n",
      "0.142578125\n",
      "alpha:  72.5\n",
      "0.14713541666666666\n",
      "alpha:  73.0\n",
      "0.14713541666666666\n",
      "alpha:  73.5\n",
      "0.14713541666666666\n",
      "alpha:  74.0\n",
      "0.14713541666666666\n",
      "alpha:  74.5\n",
      "0.14713541666666666\n",
      "alpha:  75.0\n",
      "0.146484375\n",
      "alpha:  75.5\n",
      "0.146484375\n",
      "alpha:  76.0\n",
      "0.146484375\n",
      "alpha:  76.5\n",
      "0.146484375\n",
      "alpha:  77.0\n",
      "0.146484375\n",
      "alpha:  77.5\n",
      "0.146484375\n",
      "alpha:  78.0\n",
      "0.146484375\n",
      "alpha:  78.5\n",
      "0.146484375\n",
      "alpha:  79.0\n",
      "0.14583333333333334\n",
      "alpha:  79.5\n",
      "0.14583333333333334\n",
      "alpha:  80.0\n",
      "0.14583333333333334\n",
      "alpha:  80.5\n",
      "0.14583333333333334\n",
      "alpha:  81.0\n",
      "0.14583333333333334\n",
      "alpha:  81.5\n",
      "0.14583333333333334\n",
      "alpha:  82.0\n",
      "0.14583333333333334\n",
      "alpha:  82.5\n",
      "0.14583333333333334\n",
      "alpha:  83.0\n",
      "0.14583333333333334\n",
      "alpha:  83.5\n",
      "0.14583333333333334\n",
      "alpha:  84.0\n",
      "0.14583333333333334\n",
      "alpha:  84.5\n",
      "0.14518229166666666\n",
      "alpha:  85.0\n",
      "0.14518229166666666\n",
      "alpha:  85.5\n",
      "0.14518229166666666\n",
      "alpha:  86.0\n",
      "0.14518229166666666\n",
      "alpha:  86.5\n",
      "0.14518229166666666\n",
      "alpha:  87.0\n",
      "0.14583333333333334\n",
      "alpha:  87.5\n",
      "0.146484375\n",
      "alpha:  88.0\n",
      "0.146484375\n",
      "alpha:  88.5\n",
      "0.146484375\n",
      "alpha:  89.0\n",
      "0.146484375\n",
      "alpha:  89.5\n",
      "0.14713541666666666\n",
      "alpha:  90.0\n",
      "0.14713541666666666\n",
      "alpha:  90.5\n",
      "0.14713541666666666\n",
      "alpha:  91.0\n",
      "0.146484375\n",
      "alpha:  91.5\n",
      "0.14713541666666666\n",
      "alpha:  92.0\n",
      "0.14713541666666666\n",
      "alpha:  92.5\n",
      "0.14713541666666666\n",
      "alpha:  93.0\n",
      "0.14713541666666666\n",
      "alpha:  93.5\n",
      "0.14713541666666666\n",
      "alpha:  94.0\n",
      "0.14713541666666666\n",
      "alpha:  94.5\n",
      "0.14713541666666666\n",
      "alpha:  95.0\n",
      "0.14713541666666666\n",
      "alpha:  95.5\n",
      "0.14713541666666666\n",
      "alpha:  96.0\n",
      "0.14713541666666666\n",
      "alpha:  96.5\n",
      "0.14713541666666666\n",
      "alpha:  97.0\n",
      "0.14713541666666666\n",
      "alpha:  97.5\n",
      "0.14713541666666666\n",
      "alpha:  98.0\n",
      "0.14713541666666666\n",
      "alpha:  98.5\n",
      "0.14713541666666666\n",
      "alpha:  99.0\n",
      "0.146484375\n",
      "alpha:  99.5\n",
      "0.146484375\n",
      "alpha:  100.0\n",
      "0.146484375\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.nditer(alphaArr):\n",
    "\tprint('alpha: ', alpha)\n",
    "\tpredictedRes = np.zeros(xtest.shape[0])\n",
    "\tfor i in range(xtest.shape[0]):\n",
    "\t\tfeatureVector = xtest[i]\n",
    "\t\tpredictedRes[i] = calcPosteriorProdictiveDist(alpha, naiveBayesClassifier, lambdaMl, featureVector)\n",
    "\t\t#print('predicted: ', predictedRes[i])\n",
    "\tpredictedRes = predictedRes.astype(int)\n",
    "\tytest = ytest.flatten().astype(int)\n",
    "\terror = np.mean( predictedRes != ytest )\n",
    "\tprint(error)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
